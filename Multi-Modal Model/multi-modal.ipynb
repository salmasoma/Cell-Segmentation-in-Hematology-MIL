{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('/home/salma.hassan/AI702/MaskAttention/features.csv')\n",
    "testing = pd.read_csv('/home/salma.hassan/AI702/MaskAttention/features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(cancer_type):\n",
    "    return \"A photo of leukemia cancer\"\n",
    "\n",
    "training['Description'] = training['Target'].apply(description)\n",
    "testing['Description'] = testing['Target'].apply(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['Target'] = label_encoder.fit_transform(training['Target'])\n",
    "testing['Target'] = label_encoder.fit_transform(testing['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = training\n",
    "test_data = testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('float', [])  : 96 | ['original_shape2D_Elongation', 'original_shape2D_MajorAxisLength', 'original_shape2D_MaximumDiameter', 'original_shape2D_MeshSurface', 'original_shape2D_MinorAxisLength', ...]\n",
      "('int', [])    :  7 | ['original_shape2D_PixelSurface', 'original_firstorder_Energy', 'original_firstorder_Maximum', 'original_firstorder_Minimum', 'original_firstorder_Range', ...]\n",
      "('object', []) :  2 | ['Image', 'Description']\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import FeatureMetadata\n",
    "feature_metadata = FeatureMetadata.from_df(train_data)\n",
    "\n",
    "print(feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Target'\n",
    "image_col = 'Image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('float', [])        : 96 | ['original_shape2D_Elongation', 'original_shape2D_MajorAxisLength', 'original_shape2D_MaximumDiameter', 'original_shape2D_MeshSurface', 'original_shape2D_MinorAxisLength', ...]\n",
      "('int', [])          :  7 | ['original_shape2D_PixelSurface', 'original_firstorder_Energy', 'original_firstorder_Maximum', 'original_firstorder_Minimum', 'original_firstorder_Range', ...]\n",
      "('object', [])       :  1 | ['Image']\n",
      "('object', ['text']) :  1 | ['Description']\n"
     ]
    }
   ],
   "source": [
    "feature_metadata = feature_metadata.add_special_types({\"Description\": ['text']})\n",
    "\n",
    "print(feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('float', [])              : 96 | ['original_shape2D_Elongation', 'original_shape2D_MajorAxisLength', 'original_shape2D_MaximumDiameter', 'original_shape2D_MeshSurface', 'original_shape2D_MinorAxisLength', ...]\n",
      "('int', [])                :  7 | ['original_shape2D_PixelSurface', 'original_firstorder_Energy', 'original_firstorder_Maximum', 'original_firstorder_Minimum', 'original_firstorder_Range', ...]\n",
      "('object', ['image_path']) :  1 | ['Image']\n",
      "('object', ['text'])       :  1 | ['Description']\n"
     ]
    }
   ],
   "source": [
    "feature_metadata = feature_metadata.add_special_types({image_col: ['image_path']})\n",
    "\n",
    "print(feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN_TORCH': {},\n",
       " 'GBM': [{},\n",
       "  {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
       "  'GBMLarge'],\n",
       " 'CAT': {},\n",
       " 'XGB': {},\n",
       " 'AG_AUTOMM': {},\n",
       " 'VW': {}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\n",
    "hyperparameters = get_hyperparameter_config('multimodal')\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240425_113053\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240425_113053\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Tue Sep 26 09:05:21 UTC 2023\n",
      "CPU Count:          32\n",
      "Memory Avail:       112.94 GB / 125.55 GB (90.0%)\n",
      "Disk Space Avail:   123616.28 GB / 238713.04 GB (51.8%)\n",
      "===================================================\n",
      "Train Data Rows:    2715\n",
      "Train Data Columns: 104\n",
      "Label Column:       Target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t5 unique label values:  [3, 4, 0, 2, 1]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    115649.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.68 MB (0.0% of available memory)\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting IsNanFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Description']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['original_firstorder_TotalEnergy']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 1 | ['original_firstorder_TotalEnergy']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])              : 96 | ['original_shape2D_Elongation', 'original_shape2D_MajorAxisLength', 'original_shape2D_MaximumDiameter', 'original_shape2D_MeshSurface', 'original_shape2D_MinorAxisLength', ...]\n",
      "\t\t('int', [])                :  5 | ['original_shape2D_PixelSurface', 'original_firstorder_Energy', 'original_firstorder_Maximum', 'original_firstorder_Minimum', 'original_firstorder_Range']\n",
      "\t\t('object', ['image_path']) :  1 | ['Image']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])              : 96 | ['original_shape2D_Elongation', 'original_shape2D_MajorAxisLength', 'original_shape2D_MaximumDiameter', 'original_shape2D_MeshSurface', 'original_shape2D_MinorAxisLength', ...]\n",
      "\t\t('int', [])                :  5 | ['original_shape2D_PixelSurface', 'original_firstorder_Energy', 'original_firstorder_Maximum', 'original_firstorder_Minimum', 'original_firstorder_Range']\n",
      "\t\t('object', ['image_path']) :  1 | ['Image']\n",
      "\t0.3s = Fit runtime\n",
      "\t102 features in original data used to generate 102 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.45 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1841620626151013, Train Rows: 2215, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'VW': {},\n",
      "}\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM ... Training model for up to 899.72s of the 899.72s of remaining time.\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t13.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 886.1s of the 886.1s of remaining time.\n",
      "\t0.848\t = Validation score   (accuracy)\n",
      "\t14.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 871.92s of the 871.92s of remaining time.\n",
      "\t0.844\t = Validation score   (accuracy)\n",
      "\t42.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 829.65s of the 829.65s of remaining time.\n",
      "\t0.848\t = Validation score   (accuracy)\n",
      "\t8.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 820.9s of the 820.9s of remaining time.\n",
      "\t0.854\t = Validation score   (accuracy)\n",
      "\t8.03s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit ... Training model for up to 812.81s of the 812.81s of remaining time.\n",
      "\tWarning: Exception caused VowpalWabbit to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "Fitting model: LightGBMLarge ... Training model for up to 812.75s of the 812.75s of remaining time.\n",
      "\t0.832\t = Validation score   (accuracy)\n",
      "\t36.68s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor ... Training model for up to 775.78s of the 775.78s of remaining time.\n",
      "\tWarning: Exception caused MultiModalPredictor to fail during training... Skipping this model.\n",
      "\t\tSpecified num_gpus=0 per MultiModalPredictorModel is less than minimum num_gpus=1\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/salma.hassan/miniconda3/envs/auto/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/salma.hassan/miniconda3/envs/auto/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/salma.hassan/miniconda3/envs/auto/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/salma.hassan/miniconda3/envs/auto/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/salma.hassan/miniconda3/envs/auto/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/salma.hassan/miniconda3/envs/auto/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 710, in _calculate_total_resources\n",
      "    assert (\n",
      "AssertionError: Specified num_gpus=0 per MultiModalPredictorModel is less than minimum num_gpus=1\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 775.71s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.5, 'CatBoost': 0.25, 'NeuralNetTorch': 0.25}\n",
      "\t0.862\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 124.45s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240425_113053\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    feature_metadata=feature_metadata,\n",
    "    time_limit=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (8.1.7)\n",
      "Requirement already satisfied: filelock in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (3.13.4)\n",
      "Requirement already satisfied: jsonschema in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (4.21.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (1.0.8)\n",
      "Requirement already satisfied: packaging in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (4.25.3)\n",
      "Requirement already satisfied: pyyaml in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (1.4.1)\n",
      "Requirement already satisfied: requests in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from ray) (2.28.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from jsonschema->ray) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from jsonschema->ray) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from jsonschema->ray) (0.35.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from jsonschema->ray) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from requests->ray) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from requests->ray) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from requests->ray) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages (from requests->ray) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.609854</td>\n",
       "      <td>0.854</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.053071</td>\n",
       "      <td>0.044838</td>\n",
       "      <td>8.033693</td>\n",
       "      <td>0.053071</td>\n",
       "      <td>0.044838</td>\n",
       "      <td>8.033693</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.603196</td>\n",
       "      <td>0.848</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>14.111922</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>14.111922</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.603196</td>\n",
       "      <td>0.862</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.114396</td>\n",
       "      <td>0.064757</td>\n",
       "      <td>59.080343</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.091950</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.588549</td>\n",
       "      <td>0.844</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>42.249317</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>42.249317</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.584554</td>\n",
       "      <td>0.848</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>8.705383</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>8.705383</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.580559</td>\n",
       "      <td>0.850</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>13.556908</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>13.556908</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.580559</td>\n",
       "      <td>0.832</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.098627</td>\n",
       "      <td>0.030213</td>\n",
       "      <td>36.682438</td>\n",
       "      <td>0.098627</td>\n",
       "      <td>0.030213</td>\n",
       "      <td>36.682438</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0       NeuralNetTorch    0.609854      0.854    accuracy        0.053071   \n",
       "1           LightGBMXT    0.603196      0.848    accuracy        0.030510   \n",
       "2  WeightedEnsemble_L2    0.603196      0.862    accuracy        0.114396   \n",
       "3             CatBoost    0.588549      0.844    accuracy        0.015235   \n",
       "4              XGBoost    0.584554      0.848    accuracy        0.041000   \n",
       "5             LightGBM    0.580559      0.850    accuracy        0.029383   \n",
       "6        LightGBMLarge    0.580559      0.832    accuracy        0.098627   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.044838   8.033693                 0.053071                0.044838   \n",
       "1       0.013040  14.111922                 0.030510                0.013040   \n",
       "2       0.064757  59.080343                 0.005090                0.000812   \n",
       "3       0.010361  42.249317                 0.015235                0.010361   \n",
       "4       0.008746   8.705383                 0.041000                0.008746   \n",
       "5       0.012740  13.556908                 0.029383                0.012740   \n",
       "6       0.030213  36.682438                 0.098627                0.030213   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           8.033693            1       True          5  \n",
       "1          14.111922            1       True          2  \n",
       "2           0.091950            2       True          7  \n",
       "3          42.249317            1       True          3  \n",
       "4           8.705383            1       True          4  \n",
       "5          13.556908            1       True          1  \n",
       "6          36.682438            1       True          6  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240425_144513\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Tue Sep 26 09:05:21 UTC 2023\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.1.2+cu121\n",
      "CUDA Version:       12.1\n",
      "Memory Avail:       101.96 GB / 125.55 GB (81.2%)\n",
      "Disk Space Avail:   123535.23 GB / 238713.06 GB (51.8%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t5 unique label values:  [3, 4, 0, 2, 1]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-25 23:55:59</td></tr>\n",
       "<tr><td>Running for: </td><td>05:10:43.63        </td></tr>\n",
       "<tr><td>Memory:      </td><td>53.1/125.6 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=40<br>Bracket: Iter 4096.000: None | Iter 1024.000: None | Iter 256.000: None | Iter 64.000: None | Iter 16.000: 0.9679999947547913 | Iter 4.000: 0.9065000116825104 | Iter 1.000: 0.6069999784231186<br>Logical resource usage: 32.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  model.ft_transformer\n",
       ".num_blocks</th><th>model.names         </th><th>model.timm_image.che\n",
       "ckpoint_name                     </th><th style=\"text-align: right;\">            optimization.learnin\n",
       "g_rate</th><th>optimization.lr_sche\n",
       "dule                 </th><th style=\"text-align: right;\">   optimization.max_epo\n",
       "chs</th><th>optimization.optim_t\n",
       "ype      </th><th>optimization.top_k_a\n",
       "verage_method            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>0041264e    </td><td>TERMINATED</td><td>10.127.30.63:815496 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _0400</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000615349</td><td>linear_decay    </td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        426.685 </td><td style=\"text-align: right;\">         0.662</td></tr>\n",
       "<tr><td>e933baf3    </td><td>TERMINATED</td><td>10.127.30.63:829796 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _3fc0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000255274</td><td>cosine_decay    </td><td style=\"text-align: right;\">30</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.579 </td><td style=\"text-align: right;\">         0.166</td></tr>\n",
       "<tr><td>a218fe20    </td><td>TERMINATED</td><td>10.127.30.63:830706 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _17c0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.00088233 </td><td>cosine_decay    </td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">        980.451 </td><td style=\"text-align: right;\">         0.956</td></tr>\n",
       "<tr><td>e6babcd2    </td><td>TERMINATED</td><td>10.127.30.63:879372 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _d640</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000431951</td><td>linear_decay    </td><td style=\"text-align: right;\">20</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.6237</td><td style=\"text-align: right;\">         0.166</td></tr>\n",
       "<tr><td>e0de3932    </td><td>TERMINATED</td><td>10.127.30.63:880510 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _df00</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000418247</td><td>linear_decay    </td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">        702.126 </td><td style=\"text-align: right;\">         0.952</td></tr>\n",
       "<tr><td>de15d518    </td><td>TERMINATED</td><td>10.127.30.63:915909 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _ee00</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000264647</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        527.015 </td><td style=\"text-align: right;\">         0.968</td></tr>\n",
       "<tr><td>19646bc5    </td><td>TERMINATED</td><td>10.127.30.63:946668 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _e640</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000649003</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         32.6423</td><td style=\"text-align: right;\">         0.182</td></tr>\n",
       "<tr><td>da0b6798    </td><td>TERMINATED</td><td>10.127.30.63:948361 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _6080</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000866693</td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        532.426 </td><td style=\"text-align: right;\">         0.96 </td></tr>\n",
       "<tr><td>f88dedf5    </td><td>TERMINATED</td><td>10.127.30.63:979412 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _c600</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000449239</td><td>linear_decay    </td><td style=\"text-align: right;\">20</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         33.5764</td><td style=\"text-align: right;\">         0.176</td></tr>\n",
       "<tr><td>9297b905    </td><td>TERMINATED</td><td>10.127.30.63:981156 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _0800</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000653763</td><td>linear_decay    </td><td style=\"text-align: right;\">30</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         36.8282</td><td style=\"text-align: right;\">         0.178</td></tr>\n",
       "<tr><td>0a78ed44    </td><td>TERMINATED</td><td>10.127.30.63:982660 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _df40</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.00064765 </td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.1841</td><td style=\"text-align: right;\">         0.178</td></tr>\n",
       "<tr><td>af2035a6    </td><td>TERMINATED</td><td>10.127.30.63:983734 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _72c0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000287813</td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        126.501 </td><td style=\"text-align: right;\">         0.868</td></tr>\n",
       "<tr><td>76b5dd58    </td><td>TERMINATED</td><td>10.127.30.63:990075 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _ab00</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000102689</td><td>linear_decay    </td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.637 </td><td style=\"text-align: right;\">         0.166</td></tr>\n",
       "<tr><td>80ecea98    </td><td>TERMINATED</td><td>10.127.30.63:991630 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _3580</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000378844</td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.7395</td><td style=\"text-align: right;\">         0.17 </td></tr>\n",
       "<tr><td>0fe7ea07    </td><td>TERMINATED</td><td>10.127.30.63:993353 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _51c0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000814806</td><td>polynomial_decay</td><td style=\"text-align: right;\">20</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         39.4933</td><td style=\"text-align: right;\">         0.174</td></tr>\n",
       "<tr><td>dfdb3917    </td><td>TERMINATED</td><td>10.127.30.63:994533 </td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _0ec0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000458902</td><td>cosine_decay    </td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        118.076 </td><td style=\"text-align: right;\">         0.874</td></tr>\n",
       "<tr><td>89bdde7e    </td><td>TERMINATED</td><td>10.127.30.63:1000368</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _0dc0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000817597</td><td>cosine_decay    </td><td style=\"text-align: right;\">30</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         33.4447</td><td style=\"text-align: right;\">         0.174</td></tr>\n",
       "<tr><td>e7663d9d    </td><td>TERMINATED</td><td>10.127.30.63:1002351</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _3980</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000768349</td><td>linear_decay    </td><td style=\"text-align: right;\">30</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        130.226 </td><td style=\"text-align: right;\">         0.848</td></tr>\n",
       "<tr><td>8fd91941    </td><td>TERMINATED</td><td>10.127.30.63:1009024</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _30c0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000978625</td><td>linear_decay    </td><td style=\"text-align: right;\">30</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.8721</td><td style=\"text-align: right;\">         0.176</td></tr>\n",
       "<tr><td>fefa1b60    </td><td>TERMINATED</td><td>10.127.30.63:1010614</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _2f00</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">8.73477e-05</td><td>polynomial_decay</td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         39.9718</td><td style=\"text-align: right;\">         0.364</td></tr>\n",
       "<tr><td>587a3ed3    </td><td>TERMINATED</td><td>10.127.30.63:1012543</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _6c00</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000228378</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        472.791 </td><td style=\"text-align: right;\">         0.96 </td></tr>\n",
       "<tr><td>7e390538    </td><td>TERMINATED</td><td>10.127.30.63:1036873</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _c300</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000188034</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        619.883 </td><td style=\"text-align: right;\">         0.966</td></tr>\n",
       "<tr><td>c99c15e7    </td><td>TERMINATED</td><td>10.127.30.63:1068377</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _5340</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000953622</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         40.4724</td><td style=\"text-align: right;\">         0.444</td></tr>\n",
       "<tr><td>178a908d    </td><td>TERMINATED</td><td>10.127.30.63:1070653</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _0080</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000164829</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        133.593 </td><td style=\"text-align: right;\">         0.848</td></tr>\n",
       "<tr><td>886fa2da    </td><td>TERMINATED</td><td>10.127.30.63:1076676</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _6200</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000334514</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        626.802 </td><td style=\"text-align: right;\">         0.978</td></tr>\n",
       "<tr><td>e33eba21    </td><td>TERMINATED</td><td>10.127.30.63:1107860</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _6dc0</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">5.31262e-05</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         32.8659</td><td style=\"text-align: right;\">         0.538</td></tr>\n",
       "<tr><td>2998c2a4    </td><td>TERMINATED</td><td>10.127.30.63:1109995</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _cf40</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000309793</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        161.059 </td><td style=\"text-align: right;\">         0.862</td></tr>\n",
       "<tr><td>99b9cd34    </td><td>TERMINATED</td><td>10.127.30.63:1117167</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _54c0</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000552512</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        763.621 </td><td style=\"text-align: right;\">         0.972</td></tr>\n",
       "<tr><td>493d16f7    </td><td>TERMINATED</td><td>10.127.30.63:1150592</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _7d80</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000358857</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        154.82  </td><td style=\"text-align: right;\">         0.886</td></tr>\n",
       "<tr><td>8b0b8b8e    </td><td>TERMINATED</td><td>10.127.30.63:1157468</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _6bc0</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000560181</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        615.184 </td><td style=\"text-align: right;\">         0.938</td></tr>\n",
       "<tr><td>ded7ab74    </td><td>TERMINATED</td><td>10.127.30.63:1184910</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _c580</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000569433</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        777.35  </td><td style=\"text-align: right;\">         0.972</td></tr>\n",
       "<tr><td>934fc8f8    </td><td>TERMINATED</td><td>10.127.30.63:1217657</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _a900</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000709247</td><td>polynomial_decay</td><td style=\"text-align: right;\">30</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        145.779 </td><td style=\"text-align: right;\">         0.896</td></tr>\n",
       "<tr><td>a9e31bd0    </td><td>TERMINATED</td><td>10.127.30.63:1223912</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _9600</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000535385</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        602.75  </td><td style=\"text-align: right;\">         0.968</td></tr>\n",
       "<tr><td>f52a7ae3    </td><td>TERMINATED</td><td>10.127.30.63:1248546</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _b140</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000480815</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        153.199 </td><td style=\"text-align: right;\">         0.89 </td></tr>\n",
       "<tr><td>01603ded    </td><td>TERMINATED</td><td>10.127.30.63:1256205</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _5b80</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000338509</td><td>polynomial_decay</td><td style=\"text-align: right;\">30</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        690.96  </td><td style=\"text-align: right;\">         0.942</td></tr>\n",
       "<tr><td>ea3143a3    </td><td>TERMINATED</td><td>10.127.30.63:1283074</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _18c0</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000593751</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        664.448 </td><td style=\"text-align: right;\">         0.954</td></tr>\n",
       "<tr><td>987dd212    </td><td>TERMINATED</td><td>10.127.30.63:1310262</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _0c40</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.00050405 </td><td>polynomial_decay</td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         42.0684</td><td style=\"text-align: right;\">         0.56 </td></tr>\n",
       "<tr><td>6e6a39f7    </td><td>TERMINATED</td><td>10.127.30.63:1312370</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _b880</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000405136</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        175.802 </td><td style=\"text-align: right;\">         0.904</td></tr>\n",
       "<tr><td>0a00c30c    </td><td>TERMINATED</td><td>10.127.30.63:1319901</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _4500</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000720221</td><td>linear_decay    </td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        182.845 </td><td style=\"text-align: right;\">         0.882</td></tr>\n",
       "<tr><td>588d57c3    </td><td>TERMINATED</td><td>10.127.30.63:1327481</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _6b40</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000227325</td><td>polynomial_decay</td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">       1379.97  </td><td style=\"text-align: right;\">         0.962</td></tr>\n",
       "<tr><td>705d96cc    </td><td>TERMINATED</td><td>10.127.30.63:1377569</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _7840</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.00061719 </td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        240.469 </td><td style=\"text-align: right;\">         0.886</td></tr>\n",
       "<tr><td>3cda3dd7    </td><td>TERMINATED</td><td>10.127.30.63:1385221</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _8f00</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000415191</td><td>linear_decay    </td><td style=\"text-align: right;\">30</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         53.7411</td><td style=\"text-align: right;\">         0.59 </td></tr>\n",
       "<tr><td>ea452bd1    </td><td>TERMINATED</td><td>10.127.30.63:1387772</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _55c0</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000153169</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         48.468 </td><td style=\"text-align: right;\">         0.168</td></tr>\n",
       "<tr><td>a4e141a2    </td><td>TERMINATED</td><td>10.127.30.63:1389608</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _7600</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000704799</td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        765.261 </td><td style=\"text-align: right;\">         0.958</td></tr>\n",
       "<tr><td>33b3791d    </td><td>TERMINATED</td><td>10.127.30.63:1416667</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _7d00</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.00050832 </td><td>polynomial_decay</td><td style=\"text-align: right;\">20</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         62.4785</td><td style=\"text-align: right;\">         0.168</td></tr>\n",
       "<tr><td>580c2c89    </td><td>TERMINATED</td><td>10.127.30.63:1418499</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _b600</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000916343</td><td>linear_decay    </td><td style=\"text-align: right;\">10</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         59.6507</td><td style=\"text-align: right;\">         0.474</td></tr>\n",
       "<tr><td>b906260a    </td><td>TERMINATED</td><td>10.127.30.63:1420815</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _7640</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000322298</td><td>cosine_decay    </td><td style=\"text-align: right;\">30</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        988.518 </td><td style=\"text-align: right;\">         0.936</td></tr>\n",
       "<tr><td>9e87663f    </td><td>TERMINATED</td><td>10.127.30.63:1449341</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _5b00</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000450979</td><td>polynomial_decay</td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        117.272 </td><td style=\"text-align: right;\">         0.176</td></tr>\n",
       "<tr><td>05192fd9    </td><td>TERMINATED</td><td>10.127.30.63:1457375</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _8440</td><td>convnext_base_i_e670</td><td style=\"text-align: right;\">0.000281764</td><td>linear_decay    </td><td style=\"text-align: right;\">20</td><td>adamw</td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        104.394 </td><td style=\"text-align: right;\">         0.588</td></tr>\n",
       "<tr><td>308a4dfa    </td><td>TERMINATED</td><td>10.127.30.63:1462320</td><td style=\"text-align: right;\">7</td><td>(&#x27;timm_image&#x27;, _bac0</td><td>swin_base_patch_4df0</td><td style=\"text-align: right;\">0.000591452</td><td>cosine_decay    </td><td style=\"text-align: right;\">10</td><td>sgd  </td><td>greedy_soup</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         97.455 </td><td style=\"text-align: right;\">         0.182</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>should_checkpoint  </th><th style=\"text-align: right;\">  val_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>0041264e    </td><td>True               </td><td style=\"text-align: right;\">         0.662</td></tr>\n",
       "<tr><td>01603ded    </td><td>True               </td><td style=\"text-align: right;\">         0.942</td></tr>\n",
       "<tr><td>05192fd9    </td><td>True               </td><td style=\"text-align: right;\">         0.588</td></tr>\n",
       "<tr><td>0a00c30c    </td><td>True               </td><td style=\"text-align: right;\">         0.882</td></tr>\n",
       "<tr><td>0a78ed44    </td><td>True               </td><td style=\"text-align: right;\">         0.178</td></tr>\n",
       "<tr><td>0fe7ea07    </td><td>True               </td><td style=\"text-align: right;\">         0.174</td></tr>\n",
       "<tr><td>178a908d    </td><td>True               </td><td style=\"text-align: right;\">         0.848</td></tr>\n",
       "<tr><td>19646bc5    </td><td>True               </td><td style=\"text-align: right;\">         0.182</td></tr>\n",
       "<tr><td>2998c2a4    </td><td>True               </td><td style=\"text-align: right;\">         0.862</td></tr>\n",
       "<tr><td>308a4dfa    </td><td>True               </td><td style=\"text-align: right;\">         0.182</td></tr>\n",
       "<tr><td>33b3791d    </td><td>True               </td><td style=\"text-align: right;\">         0.168</td></tr>\n",
       "<tr><td>3cda3dd7    </td><td>True               </td><td style=\"text-align: right;\">         0.59 </td></tr>\n",
       "<tr><td>493d16f7    </td><td>True               </td><td style=\"text-align: right;\">         0.886</td></tr>\n",
       "<tr><td>580c2c89    </td><td>True               </td><td style=\"text-align: right;\">         0.474</td></tr>\n",
       "<tr><td>587a3ed3    </td><td>True               </td><td style=\"text-align: right;\">         0.96 </td></tr>\n",
       "<tr><td>588d57c3    </td><td>True               </td><td style=\"text-align: right;\">         0.962</td></tr>\n",
       "<tr><td>6e6a39f7    </td><td>True               </td><td style=\"text-align: right;\">         0.904</td></tr>\n",
       "<tr><td>705d96cc    </td><td>True               </td><td style=\"text-align: right;\">         0.886</td></tr>\n",
       "<tr><td>76b5dd58    </td><td>True               </td><td style=\"text-align: right;\">         0.166</td></tr>\n",
       "<tr><td>7e390538    </td><td>True               </td><td style=\"text-align: right;\">         0.966</td></tr>\n",
       "<tr><td>80ecea98    </td><td>True               </td><td style=\"text-align: right;\">         0.17 </td></tr>\n",
       "<tr><td>886fa2da    </td><td>True               </td><td style=\"text-align: right;\">         0.978</td></tr>\n",
       "<tr><td>89bdde7e    </td><td>True               </td><td style=\"text-align: right;\">         0.174</td></tr>\n",
       "<tr><td>8b0b8b8e    </td><td>True               </td><td style=\"text-align: right;\">         0.938</td></tr>\n",
       "<tr><td>8fd91941    </td><td>True               </td><td style=\"text-align: right;\">         0.176</td></tr>\n",
       "<tr><td>9297b905    </td><td>True               </td><td style=\"text-align: right;\">         0.178</td></tr>\n",
       "<tr><td>934fc8f8    </td><td>True               </td><td style=\"text-align: right;\">         0.896</td></tr>\n",
       "<tr><td>987dd212    </td><td>True               </td><td style=\"text-align: right;\">         0.56 </td></tr>\n",
       "<tr><td>99b9cd34    </td><td>True               </td><td style=\"text-align: right;\">         0.972</td></tr>\n",
       "<tr><td>9e87663f    </td><td>True               </td><td style=\"text-align: right;\">         0.176</td></tr>\n",
       "<tr><td>a218fe20    </td><td>True               </td><td style=\"text-align: right;\">         0.956</td></tr>\n",
       "<tr><td>a4e141a2    </td><td>True               </td><td style=\"text-align: right;\">         0.958</td></tr>\n",
       "<tr><td>a9e31bd0    </td><td>True               </td><td style=\"text-align: right;\">         0.968</td></tr>\n",
       "<tr><td>af2035a6    </td><td>True               </td><td style=\"text-align: right;\">         0.868</td></tr>\n",
       "<tr><td>b906260a    </td><td>True               </td><td style=\"text-align: right;\">         0.936</td></tr>\n",
       "<tr><td>c99c15e7    </td><td>True               </td><td style=\"text-align: right;\">         0.444</td></tr>\n",
       "<tr><td>da0b6798    </td><td>True               </td><td style=\"text-align: right;\">         0.96 </td></tr>\n",
       "<tr><td>de15d518    </td><td>True               </td><td style=\"text-align: right;\">         0.968</td></tr>\n",
       "<tr><td>ded7ab74    </td><td>True               </td><td style=\"text-align: right;\">         0.972</td></tr>\n",
       "<tr><td>dfdb3917    </td><td>True               </td><td style=\"text-align: right;\">         0.874</td></tr>\n",
       "<tr><td>e0de3932    </td><td>True               </td><td style=\"text-align: right;\">         0.952</td></tr>\n",
       "<tr><td>e33eba21    </td><td>True               </td><td style=\"text-align: right;\">         0.538</td></tr>\n",
       "<tr><td>e6babcd2    </td><td>True               </td><td style=\"text-align: right;\">         0.166</td></tr>\n",
       "<tr><td>e7663d9d    </td><td>True               </td><td style=\"text-align: right;\">         0.848</td></tr>\n",
       "<tr><td>e933baf3    </td><td>True               </td><td style=\"text-align: right;\">         0.166</td></tr>\n",
       "<tr><td>ea3143a3    </td><td>True               </td><td style=\"text-align: right;\">         0.954</td></tr>\n",
       "<tr><td>ea452bd1    </td><td>True               </td><td style=\"text-align: right;\">         0.168</td></tr>\n",
       "<tr><td>f52a7ae3    </td><td>True               </td><td style=\"text-align: right;\">         0.89 </td></tr>\n",
       "<tr><td>f88dedf5    </td><td>True               </td><td style=\"text-align: right;\">         0.176</td></tr>\n",
       "<tr><td>fefa1b60    </td><td>True               </td><td style=\"text-align: right;\">         0.364</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing non-optimal trials and only keep the best one.\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22ft1k to current convnext_base.fb_in22k_ft_in1k.\n",
      "  model = create_fn(\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 16/16 [00:02<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 16/16 [00:02<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. \n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_144513\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x152058ade250>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "predictor_hpo = MultiModalPredictor(label=\"Target\")\n",
    "# \"model.timm_image.checkpoint_name\": tune.choice([\"ghostnet_100\", \"mobilenetv3_large_100\", \"swin_base_patch4_window7_224\", \"convnext_base_in22ft1k\"]),\n",
    "# predictor.fit(hyperparameters={\"model.names\": [\"hf_text\", \"timm_image\", \"clip\", \"categorical_mlp\", \"numerical_mlp\", \"fusion_mlp\"]})\n",
    "\n",
    "hyperparameters = {\n",
    "            \"optimization.learning_rate\": tune.uniform(0.00005, 0.001),\n",
    "            \"optimization.optim_type\": tune.choice([\"adamw\", \"sgd\"]),\n",
    "            \"optimization.max_epochs\": tune.choice([\"10\", \"20\", \"30\"]), \n",
    "            \"optimization.lr_schedule\": tune.choice([\"cosine_decay\", \"polynomial_decay\", \"linear_decay\"]),\n",
    "            \"model.timm_image.checkpoint_name\": tune.choice([\"swin_base_patch4_window7_224\", \"convnext_base_in22ft1k\"]),\n",
    "            \"optimization.top_k_average_method\": \"greedy_soup\",\n",
    "            \"model.names\": tune.choice([ \"timm_image\", \"clip\", \"ft_transformer\", \"fusion_mlp\"]),\n",
    "            \"model.ft_transformer.num_blocks\": 7\n",
    "}\n",
    "hyperparameter_tune_kwargs = {\n",
    "    \"searcher\": \"bayes\", # random\n",
    "    \"scheduler\": \"ASHA\",\n",
    "    \"num_trials\": 50,\n",
    "}\n",
    "predictor_hpo.fit(\n",
    "        train_data=train_data,\n",
    "        hyperparameters=hyperparameters,\n",
    "        hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22ft1k to current convnext_base.fb_in22k_ft_in1k.\n",
      "  model = create_fn(\n",
      "Load pretrained checkpoint: /home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_144513/model.ckpt\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 24/24 [00:03<00:00,  7.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.715046604527297,\n",
       " 'balanced_accuracy': 0.7054891637828741,\n",
       " 'f1_weighted': 0.7300518829497755,\n",
       " 'precision_weighted': 0.7711878872002697,\n",
       " 'recall_weighted': 0.715046604527297}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_hpo = MultiModalPredictor.load(\"/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_144513\")\n",
    "scores = predictor_hpo.evaluate(testing, metrics=[\"accuracy\", \"balanced_accuracy\", \"f1_weighted\", \"precision_weighted\", \"recall_weighted\"])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22ft1k to current convnext_base.fb_in22k_ft_in1k.\n",
      "  model = create_fn(\n",
      "Load pretrained checkpoint: /home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_133025/model.ckpt\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 24/24 [00:09<00:00,  2.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7336884154460719,\n",
       " 'balanced_accuracy': 0.7489728351849223,\n",
       " 'f1_weighted': 0.7569923924906933,\n",
       " 'precision_weighted': 0.8175700298407225,\n",
       " 'recall_weighted': 0.7336884154460719}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_hpo = MultiModalPredictor.load(\"/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_133025\")\n",
    "scores = predictor_hpo.evaluate(testing, metrics=[\"accuracy\", \"balanced_accuracy\", \"f1_weighted\", \"precision_weighted\", \"recall_weighted\"])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240425_201950\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Tue Sep 26 09:05:21 UTC 2023\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.1.2+cu121\n",
      "CUDA Version:       12.1\n",
      "Memory Avail:       71.36 GB / 125.55 GB (56.8%)\n",
      "Disk Space Avail:   123181.84 GB / 238713.09 GB (51.6%)\n",
      "===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "AutoMM starts to create your model. \n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950\n",
      "    ```\n",
      "\n",
      "[rank: 0] Seed set to 0\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22ft1k to current convnext_base.fb_in22k_ft_in1k.\n",
      "  model = create_fn(\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "GPU 0 Name: Quadro RTX 6000\n",
      "GPU 0 Memory: 0.8GB/24.0GB (Used/Total)\n",
      "\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 89.9 M\n",
      "1 | validation_metric | MulticlassAccuracy  | 0     \n",
      "2 | loss_func         | CrossEntropyLoss    | 0     \n",
      "----------------------------------------------------------\n",
      "89.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "89.9 M    Total params\n",
      "359.775   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|     | 138/277 [00:13<00:13, 10.36it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_accuracy' reached 0.36800 (best 0.36800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=0-step=8.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 276/277 [00:45<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 17: 'val_accuracy' reached 0.68800 (best 0.68800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=0-step=17.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|     | 138/277 [00:18<00:18,  7.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 26: 'val_accuracy' reached 0.78600 (best 0.78600), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=1-step=26.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 276/277 [00:48<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 35: 'val_accuracy' reached 0.86200 (best 0.86200), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=1-step=35.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|     | 138/277 [00:15<00:15,  9.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 44: 'val_accuracy' reached 0.87800 (best 0.87800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=2-step=44.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 276/277 [00:43<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 53: 'val_accuracy' reached 0.91600 (best 0.91600), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=2-step=53.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|     | 138/277 [00:16<00:16,  8.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 62: 'val_accuracy' reached 0.92000 (best 0.92000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=3-step=62.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 276/277 [00:42<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 71: 'val_accuracy' reached 0.94000 (best 0.94000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=3-step=71.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|     | 138/277 [00:15<00:15,  8.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 80: 'val_accuracy' reached 0.94000 (best 0.94000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=4-step=80.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 276/277 [00:41<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 89: 'val_accuracy' reached 0.95000 (best 0.95000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=4-step=89.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|     | 138/277 [00:11<00:12, 11.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 98: 'val_accuracy' reached 0.94600 (best 0.95000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=5-step=98.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|| 276/277 [00:38<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 107: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|     | 138/277 [00:12<00:12, 11.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 116: 'val_accuracy' reached 0.94400 (best 0.95000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=6-step=116.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|| 276/277 [00:39<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 125: 'val_accuracy' reached 0.95400 (best 0.95400), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=6-step=125.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|     | 138/277 [00:16<00:16,  8.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 134: 'val_accuracy' reached 0.96800 (best 0.96800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=7-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|| 276/277 [00:44<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 143: 'val_accuracy' reached 0.96800 (best 0.96800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=7-step=143.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|     | 138/277 [00:15<00:15,  9.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 152: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|| 276/277 [00:39<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 161: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|     | 138/277 [00:13<00:13, 10.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 170: 'val_accuracy' reached 0.95600 (best 0.96800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=9-step=170.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 276/277 [00:42<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 179: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  50%|     | 138/277 [00:12<00:12, 11.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 188: 'val_accuracy' reached 0.95800 (best 0.96800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=10-step=188.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|| 276/277 [00:38<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 197: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  50%|     | 138/277 [00:13<00:13,  9.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 206: 'val_accuracy' reached 0.97000 (best 0.97000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=11-step=206.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|| 276/277 [00:38<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 215: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  50%|     | 138/277 [00:12<00:12, 10.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 224: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|| 276/277 [00:33<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 233: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  50%|     | 138/277 [00:12<00:12, 10.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 242: 'val_accuracy' reached 0.97200 (best 0.97200), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=13-step=242.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|| 276/277 [00:38<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 251: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  50%|     | 138/277 [00:12<00:12, 10.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 260: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|| 276/277 [00:33<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 269: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  50%|     | 138/277 [00:13<00:13, 10.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 278: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|| 276/277 [00:38<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 287: 'val_accuracy' reached 0.97400 (best 0.97400), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=15-step=287.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  50%|     | 138/277 [00:14<00:14,  9.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 296: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|| 276/277 [00:35<00:00,  7.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 305: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  50%|     | 138/277 [00:14<00:14,  9.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 314: 'val_accuracy' reached 0.97800 (best 0.97800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=17-step=314.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|| 276/277 [00:41<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 323: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  50%|     | 138/277 [00:13<00:13, 10.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 332: 'val_accuracy' reached 0.97600 (best 0.97800), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=18-step=332.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|| 276/277 [00:42<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 341: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  50%|     | 138/277 [00:12<00:12, 10.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 350: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|| 276/277 [00:30<00:00,  9.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 359: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  50%|     | 138/277 [00:12<00:12, 11.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 368: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|| 276/277 [00:34<00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 377: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  50%|     | 138/277 [00:13<00:13, 10.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 386: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|| 276/277 [00:34<00:00,  8.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 395: 'val_accuracy' reached 0.98000 (best 0.98000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=21-step=395.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  50%|     | 138/277 [00:16<00:17,  8.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 404: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|| 276/277 [00:38<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 413: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  50%|     | 138/277 [00:12<00:12, 10.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 422: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|| 276/277 [00:32<00:00,  8.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 431: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  50%|     | 138/277 [00:12<00:12, 10.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 440: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|| 276/277 [00:32<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 449: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  50%|     | 138/277 [00:13<00:13, 10.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 458: 'val_accuracy' reached 0.97800 (best 0.98000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=25-step=458.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|| 276/277 [00:43<00:00,  6.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 467: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  50%|     | 138/277 [00:13<00:13, 10.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 476: 'val_accuracy' reached 0.98000 (best 0.98000), saving model to '/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950/epoch=26-step=476.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|| 276/277 [00:42<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 485: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|| 276/277 [00:50<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 16/16 [00:02<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 16/16 [00:02<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 16/16 [00:02<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. \n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/salma.hassan/AI702/MaskAttention/AutogluonModels/ag-20240425_201950\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x15202c0df580>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "label_col = \"Target\"\n",
    "predictor = MultiModalPredictor(problem_type=\"multiclass\", label=label_col)\n",
    "predictor.fit(train_data, hyperparameters = {\"model.timm_image.checkpoint_name\": \"convnext_base_in22ft1k\", \"optimization.max_epochs\": 50 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n",
      "/home/salma.hassan/miniconda3/envs/auto_gpu/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/salma.hassan/miniconda3/envs/auto_gpu/lib/pyth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 24/24 [00:06<00:00,  3.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7243675099866844}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = predictor.evaluate(testing, metrics=[\"accuracy\"])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
