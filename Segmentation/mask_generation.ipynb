{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torchsummary import summary    \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "# import wandb\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.8.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "\n",
    "# Modify the last convolutional layer\n",
    "model.classifier[4] = nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(1,1))\n",
    "\n",
    "# If there's an auxiliary classifier, modify it similarly\n",
    "if model.aux_classifier is not None:\n",
    "    model.aux_classifier[4] = nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(1,1))\n",
    "\n",
    "# load weights into the model \n",
    "model.load_state_dict(torch.load('deeplabv3_leukemia.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_aspect_ratio(image, output_size, pad_value=0):\n",
    "  \"\"\"\n",
    "  Pads an image to a specific output size while maintaining aspect ratio.\n",
    "\n",
    "  Args:\n",
    "      image: PIL image object.\n",
    "      output_size: Tuple of (height, width) for the desired output size.\n",
    "      pad_value: The value to use for padding (default: 0).\n",
    "\n",
    "  Returns:\n",
    "      A padded PIL image object.\n",
    "  \"\"\"\n",
    "  w, h = image.size\n",
    "\n",
    "  target_ratio = output_size[0] / output_size[1]\n",
    "  image_ratio = w / h\n",
    "\n",
    "  if image_ratio > target_ratio:\n",
    "    # Pad on top and bottom\n",
    "    new_h = int(w / target_ratio)\n",
    "    padding_top = (new_h - h) // 2\n",
    "    padding_bottom = new_h - h - padding_top\n",
    "  else:\n",
    "    # Pad on left and right\n",
    "    new_w = int(h * target_ratio)\n",
    "    padding_left = (new_w - w) // 2\n",
    "    padding_right = new_w - w - padding_left\n",
    "\n",
    "  padded_image = F.pad(image, (padding_left, padding_right, padding_top, padding_bottom), value=pad_value)\n",
    "  return padded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for the input images\n",
    "resize = 448\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        # A.Resize(height=resize, width=resize),\n",
    "        A.Lambda(lambda x: pad_to_aspect_ratio(x, (resize, resize))),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "# Directories\n",
    "input_folder = '/home/dawlat.akaila/Documents/DL_LABS/PROJECT/try'\n",
    "output_folder = '/home/dawlat.akaila/Documents/DL_LABS/PROJECT/try_masks'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Predict masks for images in the input folder\n",
    "with torch.no_grad():\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.tif')):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            image = np.array(image)\n",
    "\n",
    "            augmented = transform(image=image)\n",
    "            input_tensor = augmented[\"image\"].unsqueeze(0).to(device)\n",
    "\n",
    "            output = model(input_tensor)['out']\n",
    "            predicted_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
    "\n",
    "            # Convert the predicted mask to binary mask\n",
    "            binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "            # Save the predicted mask\n",
    "            mask_image = Image.fromarray(binary_mask)\n",
    "            mask_image.save(os.path.join(output_folder, filename))\n",
    "\n",
    "print(\"Mask prediction completed. Masks saved in:\", output_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
