{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW SLIDE LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Add initial subgroup assignments\n",
    "mapping = pd.read_csv('info.csv')\n",
    "#get patient id based on mapping\n",
    "def get_patient_id(filename):\n",
    "    # Remove the extension from the filename\n",
    "    base_filename = os.path.splitext(filename)[0]\n",
    "    base_filename = base_filename.split('.')[0]\n",
    "    print(base_filename)\n",
    "    \n",
    "    # Assuming 'mapping' is a DataFrame with a 'filename' column that also has extensions\n",
    "    return mapping[mapping['filename'].str.split('.').str[0] == base_filename]['patient'].values[0]\n",
    "    \n",
    "def create_csv(directory, output_file='patch_train.csv', entry_type=\"train\"):\n",
    "    label_encodings = {\"ALL\": 4, \"AML\": 1, \"CLL\": 0, \"CML\": 3, \"NORMAL\": 2}\n",
    "    current_label = 0\n",
    "\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Filename', 'Location', 'Subtype', 'Patient ID', 'label', 'train/test'])\n",
    "        \n",
    "        for dirpath, _, filenames in os.walk(directory):\n",
    "            subtype = os.path.basename(dirpath)\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "                    location = os.path.join(dirpath, filename)\n",
    "                    patient_id = get_patient_id(filename)\n",
    "\n",
    "                    if subtype not in label_encodings:\n",
    "                        label_encodings[subtype] = current_label\n",
    "                        current_label += 1\n",
    "                    label = label_encodings[subtype]\n",
    "                    writer.writerow([filename, location, subtype, patient_id, label, entry_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_train = '/l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML/patched_train'\n",
    "create_csv(directory_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_val = '/l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML/patched_val'\n",
    "create_csv(directory_path_val, output_file='patch_test.csv', entry_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Filename  \\\n",
      "0      44-22-230-0278 - 1.1.png   \n",
      "1      44-22-230-0278 - 1.2.png   \n",
      "2      44-22-230-0278 - 1.3.png   \n",
      "3      44-22-230-0278 - 1.4.png   \n",
      "4      44-22-230-0278 - 1.5.png   \n",
      "...                         ...   \n",
      "11087           Image_705.1.png   \n",
      "11088           Image_706.1.png   \n",
      "11089           Image_708.1.png   \n",
      "11090           Image_709.1.png   \n",
      "11091           Image_710.1.png   \n",
      "\n",
      "                                                Location Subtype  \\\n",
      "0      /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...     AML   \n",
      "1      /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...     AML   \n",
      "2      /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...     AML   \n",
      "3      /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...     AML   \n",
      "4      /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...     AML   \n",
      "...                                                  ...     ...   \n",
      "11087  /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...  NORMAL   \n",
      "11088  /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...  NORMAL   \n",
      "11089  /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...  NORMAL   \n",
      "11090  /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...  NORMAL   \n",
      "11091  /l/users/dawlat.akaila/DATA_MASKS/NO_REAC_APML...  NORMAL   \n",
      "\n",
      "       Patient ID_Original  label train/test Patient ID  \n",
      "0                       82      1      train       82_1  \n",
      "1                       82      1      train       82_1  \n",
      "2                       82      1      train       82_1  \n",
      "3                       82      1      train       82_1  \n",
      "4                       82      1      train       82_1  \n",
      "...                    ...    ...        ...        ...  \n",
      "11087                   93      2       test      93_10  \n",
      "11088                   93      2       test      93_10  \n",
      "11089                   93      2       test      93_10  \n",
      "11090                   93      2       test      93_10  \n",
      "11091                   93      2       test      93_10  \n",
      "\n",
      "[11092 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load CSV files\n",
    "df_train = pd.read_csv('patch_train.csv')\n",
    "df_test = pd.read_csv('patch_test.csv')\n",
    "\n",
    "# Concatenate train and test dataframes\n",
    "df_combined = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# Identify patient IDs that appear only once\n",
    "patient_id_counts = df_combined['Patient ID'].value_counts()\n",
    "single_patient_ids = patient_id_counts[patient_id_counts == 1].index\n",
    "\n",
    "# Duplicate rows for patient IDs that appear only once\n",
    "df_single_patients = df_combined[df_combined['Patient ID'].isin(single_patient_ids)]\n",
    "df_combined = pd.concat([df_combined, df_single_patients], ignore_index=True)\n",
    "\n",
    "# Optional: Save the modified dataframe to a new CSV file\n",
    "df_combined.to_csv('patches_no_apml_reactive.csv', index=False)\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
